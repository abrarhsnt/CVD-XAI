{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install shap\n",
        "!pip install graphviz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcXLvAijCbws",
        "outputId": "04c47d96-8d80-48f4-e368-723ae75e0d8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: shap in /usr/local/lib/python3.12/dist-packages (0.48.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from shap) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from shap) (1.16.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from shap) (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from shap) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.12/dist-packages (from shap) (4.67.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.12/dist-packages (from shap) (25.0)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.12/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.12/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from shap) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from shap) (4.15.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.54->shap) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->shap) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->shap) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->shap) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import os\n",
        "\n",
        "\n",
        "os.makedirs('../models/explanations/shap', exist_ok=True)\n",
        "os.makedirs('../models/explanations/local_trees', exist_ok=True)\n",
        "\n",
        "# 1. Surrogate Tree\n",
        "\n",
        "\n",
        "def load_data_and_models():\n",
        "    \"\"\"Load test data and trained models\"\"\"\n",
        "    print(\"Loading data and models...\")\n",
        "\n",
        "    # Load data\n",
        "    data_path = \"../data/processed/\"\n",
        "    X_test = np.load(f\"{data_path}X_test_scaled.npy\")\n",
        "    y_test = np.load(f\"{data_path}y_test.npy\")\n",
        "\n",
        "    # Load feature names\n",
        "    try:\n",
        "        feature_names = np.load(f\"{data_path}feature_names.npy\")\n",
        "        feature_names = [str(name) for name in feature_names]\n",
        "        print(f\" Loaded {len(feature_names)} feature names\")\n",
        "    except Exception as e:\n",
        "        print(f\" Error loading feature names: {e}\")\n",
        "        feature_names = [f'Feature_{i}' for i in range(X_test.shape[1])]\n",
        "        print(\" Using default feature names\")\n",
        "\n",
        "    # Load models\n",
        "    models = {}\n",
        "    individual_models = ['lightgbm', 'xgboost', 'random_forest', 'cnn', 'rnn']\n",
        "\n",
        "    for model_name in individual_models:\n",
        "        try:\n",
        "            model_path = f'../models/advanced_models/{model_name}'\n",
        "            if model_name in ['cnn', 'rnn']:\n",
        "                from tensorflow.keras.models import load_model\n",
        "                models[model_name] = load_model(f'{model_path}.h5')\n",
        "                print(f\" Loaded {model_name}\")\n",
        "            else:\n",
        "                with open(f'{model_path}.pkl', 'rb') as f:\n",
        "                    models[model_name] = pickle.load(f)\n",
        "                print(f\" Loaded {model_name}\")\n",
        "        except Exception as e:\n",
        "            print(f\" Could not load {model_name}: {e}\")\n",
        "\n",
        "    return X_test, y_test, feature_names, models\n",
        "\n",
        "X_test, y_test, feature_names, models = load_data_and_models()\n",
        "\n",
        "# Select working model\n",
        "working_model = None\n",
        "working_model_name = None\n",
        "\n",
        "for model_name, model_obj in models.items():\n",
        "    try:\n",
        "        if hasattr(model_obj, 'predict_proba'):\n",
        "            test_pred = model_obj.predict_proba(X_test[:1])\n",
        "            working_model = model_obj\n",
        "            working_model_name = model_name\n",
        "            print(f\" Using {model_name} for analysis\")\n",
        "            break\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "if working_model is None:\n",
        "    raise Exception(\"No working models available!\")\n",
        "\n",
        "\n",
        "\n",
        "# 2. SHAP\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"SHAP ANALYSIS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "def perform_shap_analysis(model, X_data, feature_names, model_name):\n",
        "    \"\"\"Perform comprehensive SHAP analysis\"\"\"\n",
        "    print(\" Computing SHAP values...\")\n",
        "\n",
        "    # Create explainer based on model type\n",
        "    if 'lightgbm' in model_name.lower() or 'xgboost' in model_name.lower() or 'random' in model_name.lower():\n",
        "        explainer = shap.TreeExplainer(model)\n",
        "    else:\n",
        "        explainer = shap.KernelExplainer(model.predict_proba, X_data[:100])\n",
        "\n",
        "    # Calculate SHAP values\n",
        "    shap_values = explainer.shap_values(X_data)\n",
        "\n",
        "    # Handle binary classification\n",
        "    if isinstance(shap_values, list):\n",
        "        shap_values = shap_values[1]  # Use positive class\n",
        "\n",
        "    print(f\" SHAP values computed: {shap_values.shape}\")\n",
        "\n",
        "    # Create SHAP summary plot\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    shap.summary_plot(shap_values, X_data, feature_names=feature_names, show=False)\n",
        "    plt.title(f'SHAP Summary Plot - {model_name.upper()}', fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('../models/explanations/shap/shap_summary.png', dpi=300, bbox_inches='tight')\n",
        "    plt.savefig('../models/explanations/shap/shap_summary.svg', format='svg', bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    # Create SHAP bar plot\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    shap.summary_plot(shap_values, X_data, feature_names=feature_names, plot_type=\"bar\", show=False)\n",
        "    plt.title(f'SHAP Feature Importance - {model_name.upper()}', fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('../models/explanations/shap/shap_importance.png', dpi=300, bbox_inches='tight')\n",
        "    plt.savefig('../models/explanations/shap/shap_importance.svg', format='svg', bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    return shap_values, explainer\n",
        "\n",
        "# Run SHAP analysis\n",
        "shap_values, explainer = perform_shap_analysis(working_model, X_test, feature_names, working_model_name)\n",
        "\n",
        "\n",
        "# 3. Calculate Surrogate Tree\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"SURROGATE DECISION TREE\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "def create_surrogate_tree(model, X_data, y_true, feature_names, model_name):\n",
        "    \"\"\"Create surrogate decision tree that mimics the complex model\"\"\"\n",
        "    print(\" Generating model predictions...\")\n",
        "\n",
        "    # Get predictions from complex model\n",
        "    if hasattr(model, 'predict_proba'):\n",
        "        y_pred_proba = model.predict_proba(X_data)\n",
        "        y_pred = (y_pred_proba[:, 1] > 0.5).astype(int)\n",
        "    else:\n",
        "        y_pred_raw = model.predict(X_data)\n",
        "        if len(y_pred_raw.shape) > 1:\n",
        "            y_pred = (y_pred_raw[:, 1] > 0.5).astype(int)\n",
        "        else:\n",
        "            y_pred = (y_pred_raw > 0.5).astype(int)\n",
        "\n",
        "    print(f\"Predictions generated: {len(y_pred)} samples\")\n",
        "    print(f\"Class distribution: {pd.Series(y_pred).value_counts().to_dict()}\")\n",
        "\n",
        "    # Handle feature alignment\n",
        "    n_features = min(X_data.shape[1], len(feature_names))\n",
        "    X_tree = X_data[:, :n_features]\n",
        "    feature_names_tree = feature_names[:n_features]\n",
        "\n",
        "    print(\" Training surrogate decision tree...\")\n",
        "\n",
        "    # Train surrogate tree\n",
        "    surrogate_tree = DecisionTreeClassifier(\n",
        "        max_depth=4,\n",
        "        min_samples_split=30,\n",
        "        min_samples_leaf=15,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    surrogate_tree.fit(X_tree, y_pred)\n",
        "    print(\" Surrogate tree trained successfully!\")\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = surrogate_tree.score(X_tree, y_pred)\n",
        "    print(f\"Surrogate tree accuracy: {accuracy:.3f}\")\n",
        "\n",
        "    return surrogate_tree, X_tree, feature_names_tree, y_pred, accuracy\n",
        "\n",
        "# Create surrogate tree\n",
        "surrogate_tree, X_tree, feature_names_tree, y_pred, accuracy = create_surrogate_tree(\n",
        "    working_model, X_test, y_test, feature_names, working_model_name\n",
        ")\n",
        "\n",
        "\n",
        "# 4. Visualize Surrogate Tree\n",
        "\n",
        "\n",
        "def visualize_decision_tree(tree_model, feature_names, class_names, model_name, accuracy):\n",
        "    \"\"\"Create compact decision tree visualizations\"\"\"\n",
        "    print(\"Creating tree visualizations...\")\n",
        "\n",
        "    # Main compact tree\n",
        "    plt.figure(figsize=(16, 10))\n",
        "    plot_tree(tree_model,\n",
        "             feature_names=feature_names,\n",
        "             class_names=class_names,\n",
        "             filled=True,\n",
        "             rounded=True,\n",
        "             fontsize=9,\n",
        "             proportion=True,\n",
        "             impurity=False)\n",
        "\n",
        "    plt.title(f'Surrogate Decision Tree for {model_name.upper()}\\n(Accuracy: {accuracy:.3f})',\n",
        "              fontsize=14, pad=10)\n",
        "    plt.tight_layout(pad=1.0)\n",
        "    plt.savefig('../models/explanations/local_trees/compact_decision_tree.png',\n",
        "                dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
        "    plt.savefig('../models/explanations/local_trees/compact_decision_tree.svg',\n",
        "                format='svg', bbox_inches='tight', pad_inches=0.1)\n",
        "    plt.show()\n",
        "\n",
        "    # Minimal version\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plot_tree(tree_model,\n",
        "             feature_names=feature_names,\n",
        "             class_names=['No', 'Yes'],\n",
        "             filled=True,\n",
        "             rounded=True,\n",
        "             fontsize=8,\n",
        "             proportion=True,\n",
        "             impurity=False)\n",
        "\n",
        "    plt.title(f'Minimal Tree - {model_name}', fontsize=12)\n",
        "    plt.tight_layout(pad=0.8)\n",
        "    plt.savefig('../models/explanations/local_trees/minimal_decision_tree.png',\n",
        "                dpi=300, bbox_inches='tight', pad_inches=0.05)\n",
        "    plt.savefig('../models/explanations/local_trees/minimal_decision_tree.svg',\n",
        "                format='svg', bbox_inches='tight', pad_inches=0.05)\n",
        "    plt.show()\n",
        "\n",
        "# Visualize trees\n",
        "visualize_decision_tree(surrogate_tree, feature_names_tree,\n",
        "                       ['No Heart Disease', 'Heart Disease'],\n",
        "                       working_model_name, accuracy)\n",
        "\n",
        "\n",
        "# 5. Rules and Featurees\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"DECISION RULES & FEATURE ANALYSIS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Export decision rules\n",
        "tree_rules = export_text(surrogate_tree,\n",
        "                       feature_names=feature_names_tree,\n",
        "                       decimals=2,\n",
        "                       show_weights=True)\n",
        "\n",
        "print(\"Key Decision Rules:\")\n",
        "print(\"=\" * 40)\n",
        "lines = tree_rules.split('\\n')\n",
        "for line in lines[:15]:  # Show first 15 rules\n",
        "    print(line)\n",
        "\n",
        "# Save full rules to file\n",
        "with open('../models/explanations/local_trees/decision_rules.txt', 'w') as f:\n",
        "    f.write(tree_rules)\n",
        "\n",
        "# Feature importance comparison\n",
        "print(\"\\nFEATURE IMPORTANCE COMPARISON\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# SHAP importance\n",
        "shap_importance = pd.DataFrame({\n",
        "    'feature': feature_names_tree,\n",
        "    'shap_importance': np.abs(shap_values).mean(0)[:len(feature_names_tree)]\n",
        "}).sort_values('shap_importance', ascending=False)\n",
        "\n",
        "# Surrogate tree importance\n",
        "tree_importance = pd.DataFrame({\n",
        "    'feature': feature_names_tree,\n",
        "    'tree_importance': surrogate_tree.feature_importances_\n",
        "}).sort_values('tree_importance', ascending=False)\n",
        "\n",
        "print(\"Top 10 Features - SHAP vs Tree:\")\n",
        "print(\"SHAP Importance:\")\n",
        "print(shap_importance.head(10).to_string(index=False))\n",
        "print(\"\\nTree Importance:\")\n",
        "print(tree_importance.head(10).to_string(index=False))\n",
        "\n",
        "\n",
        "# 6. Summarty\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\" COMPREHENSIVE ANALYSIS SUMMARY\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "print(f\"\"\"\n",
        "MODEL PERFORMANCE:\n",
        "------------------\n",
        "• Model Used: {working_model_name.upper()}\n",
        "• Test Samples: {len(X_test):,}\n",
        "• Surrogate Tree Accuracy: {accuracy:.3f}\n",
        "• Class Distribution: {pd.Series(y_pred).value_counts().to_dict()}\n",
        "\n",
        "KEY FINDINGS:\n",
        "-------------\n",
        "1. Primary Risk Factors: {list(tree_importance.head(3)['feature'])}\n",
        "2. Decision Depth: {surrogate_tree.get_depth()} levels\n",
        "3. Number of Leaves: {surrogate_tree.get_n_leaves()}\n",
        "4. Top SHAP Features: {list(shap_importance.head(3)['feature'])}\n",
        "\n",
        "CLINICAL INSIGHTS:\n",
        "------------------\n",
        "• The surrogate tree provides transparent decision pathways\n",
        "• {accuracy:.1%} accuracy in mimicking complex model behavior\n",
        "• Clear risk stratification rules identified\n",
        "• Suitable for clinical decision support implementation\n",
        "\n",
        "FILES CREATED:\n",
        "--------------\n",
        "• SHAP summary plots (.png, .svg)\n",
        "• Surrogate tree visualizations (.png, .svg)\n",
        "• Decision rules (text file)\n",
        "• Feature importance comparison\n",
        "\"\"\")\n",
        "\n",
        "# Save summary to file\n",
        "summary_text = f\"\"\"\n",
        "SHAP + Surrogate Tree Analysis Summary\n",
        "======================================\n",
        "\n",
        "Model: {working_model_name}\n",
        "Date: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M')}\n",
        "\n",
        "Performance Metrics:\n",
        "- Test samples: {len(X_test):,}\n",
        "- Surrogate accuracy: {accuracy:.3f}\n",
        "- Tree depth: {surrogate_tree.get_depth()}\n",
        "- Number of leaves: {surrogate_tree.get_n_leaves()}\n",
        "\n",
        "Top Features:\n",
        "- SHAP: {list(shap_importance.head(5)['feature'])}\n",
        "- Tree: {list(tree_importance.head(5)['feature'])}\n",
        "\n",
        "Key Decision Patterns:\n",
        "{tree_rules[:1000]}...\n",
        "\"\"\"\n",
        "\n",
        "with open('../models/explanations/analysis_summary.txt', 'w') as f:\n",
        "    f.write(summary_text)\n",
        "\n",
        "print(\"Analysis completed successfully!\")\n",
        "print(\"All files saved to: ../models/explanations/\")"
      ],
      "metadata": {
        "id": "boXDEo9Suv1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "77ce0bcf-1525-4d96-fe7f-ccb1b3e2c6e7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📁 Loading data and models...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '../data/processed/X_test_scaled.npy'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3624258073.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data_and_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m# Select working model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3624258073.py\u001b[0m in \u001b[0;36mload_data_and_models\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Load data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mdata_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../data/processed/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{data_path}X_test_scaled.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{data_path}y_test.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/lib/_npyio_impl.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/processed/X_test_scaled.npy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "19rCIDfjtTvS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}